# ğŸ›’ E-commerce Price Comparison Pipeline

This project is a **data pipeline for scraping product prices** from Thai e-commerce websites, comparing them, and **automatically uploading the results to Google Drive** as an Excel file.

### âœ… Features

- Scrapes prices from:
  - Lazada
  - eBay
  - Power Buy (1 page limit)
- Uses Selenium via remote Chrome container (`selenium/standalone-chrome`)
- Runs daily via Apache Airflow
- Outputs merged results in Excel, sorted by price
- Uploads the file to a specified folder in Google Drive

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ scrape_compare_upload.py        # Main Airflow DAG
â”œâ”€â”€ gfrive_uploader/
â”‚   â”œâ”€â”€ upload_to_gdrive.py             # Utility for uploading to Google Drive
â”œâ”€â”€ output/                             # Excel output files (mounted)
â”œâ”€â”€ creds/
â”‚   â””â”€â”€ service_account.json            # GDrive API credentials
â””â”€â”€ scrapers/
â”‚   â”œâ”€â”€ lazada_scraper.py
â”‚   â”œâ”€â”€ ebay_scraper.py
â”‚   â”œâ”€â”€ powerbuy_scraper.py
â”‚   â””â”€â”€ compare.py                      # Merges and exports results
â”‚
â”œâ”€â”€ Dockerfile                          # Airflow version + pip requirements
â”œâ”€â”€ docker-compose.yml                  # Services: Airflow, Selenium Chrome
â””â”€â”€ requirements.txt                    # Python dependencies
```

---

## ğŸš€ Quick Start

### 1. Prepare environment variables
Copy the template .env file and update the values as needed:
```bash
cp .env_template .env
```
ğŸ’¡ Edit .env to set things like your Google Drive folder ID

### 2. Start the system
Build and run the containers:
```bash
docker-compose up -d --build
```

Visit Airflow UI at: [http://localhost:8080](http://localhost:8080)

Default login:  
- **Username:** `airflow`  
- **Password:** `airflow`

---

## âš™ï¸ Configuration

You can change the product to search by modifying the `search_query` in:
```python
# dags/scrape_compare_upload.py
search_query = "smart watch"
```
or while manually executing DAGs with config:
```
{"search_query":"smart watch"}
```

---

## ğŸ§ª Sample Output

Excel file will be named:
```
product_prices_YYYY-MM-DD.xlsx
```
And uploaded to the specified Google Drive folder.

Each row includes:
- Product name
- Price (float)
- Product link
- Source (Lazada, Power Buy)

---

## ğŸ›  Tech Stack

- Apache Airflow
- Python + Selenium
- Pandas
- Google Drive API (via `pydrive2`)
- Docker / docker-compose

---

## ğŸ§¼ Notes

- PowerBuy currently supports scraping only the first page, limiting the maximum number of products retrieved to 50..
- Shopee was avoided due to aggressive bot protection (JavaScript rendering + CAPTCHA).

---